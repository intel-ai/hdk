{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "import pyhdk\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet\n",
    "import pyarrow.csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "hdk = pyhdk.hdk.HDK(\n",
    "    enable_heterogeneous=True,\n",
    "    force_heterogeneous_distribution=True,\n",
    "    enable_multifrag_heterogeneous=True,\n",
    "    # enable_debug_timer=True,\n",
    "    # debug_logs=\"INFO\" # generates log file, DEBUG2 for more verbosity \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def import_hdk_pyarrow(arrow_tbl, hdk_tbl_name, fragment_size, overwrite=True):\n",
    "    \"\"\"\n",
    "    Wrapper that imports a pyarrow table to HDK with the given fragment size.\n",
    "        overwrite: By default overwrites previously existing table.\n",
    "    \"\"\"\n",
    "    if overwrite:\n",
    "        hdk.drop_table(hdk_tbl_name)\n",
    "    start_timer = time.perf_counter()\n",
    "    hdk_tbl = hdk.import_arrow(arrow_tbl, hdk_tbl_name, fragment_size)\n",
    "    print(f\"[PyHDK] Importing pyarrow table: {(time.perf_counter()-start_timer):.4f}s\")\n",
    "    return hdk_tbl\n",
    "\n",
    "\n",
    "def fragment_size_calc(num_rows):\n",
    "    \"\"\"Taken from Modin, you can experiment with it.\"\"\"\n",
    "    cpu_count = os.cpu_count()\n",
    "    if cpu_count is not None:\n",
    "        fragment_size = num_rows // cpu_count\n",
    "        fragment_size = min(fragment_size, 2**25)\n",
    "        fragment_size = max(fragment_size, 2**18)\n",
    "        return fragment_size\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def fragment_size_test_range(num_rows):\n",
    "    \"\"\"\n",
    "    Take two power of two steps around default frag_size: [x/4,x/2,x,x*2,x*4].\n",
    "    \"\"\"\n",
    "    res_range = []\n",
    "    default_fragment_size = fragment_size_calc(num_rows)\n",
    "    print(f\"Default fragment_size={default_fragment_size}\")\n",
    "    power_two_steps = 2\n",
    "    range_start = default_fragment_size//(2**power_two_steps)\n",
    "    range_end = default_fragment_size*(2**power_two_steps)\n",
    "    fragment_size = range_start\n",
    "    while fragment_size < range_end+1:\n",
    "        res_range.append(fragment_size)\n",
    "        fragment_size *= 2\n",
    "    return res_range\n",
    "\n",
    "\n",
    "def run_single_q_all_props(sql, q_name, prop_step, n_iters, clear_gpu_mem=False):\n",
    "    \"\"\"\n",
    "    Runs SQL query multiple times at each proportion, feel free try and experiment with loops order.\n",
    "        clear_gpu_mem: when True, clear GPU memory between runs\n",
    "    \"\"\"\n",
    "    col_names = [\"GPU_prop\", q_name]\n",
    "    prop_time = {col_names[0] : [], col_names[1]: []}\n",
    "    # Walking over proportions\n",
    "    for gpu_proportion in range(0, 101, prop_step):\n",
    "        # Multiple iterations\n",
    "        for _ in range(1, n_iters + 1):\n",
    "            query_start = time.perf_counter()\n",
    "            result = hdk.sql(sql, {\"forced_gpu_proportion\":gpu_proportion})\n",
    "            query_finish = time.perf_counter()\n",
    "            prop_time[col_names[0]].append(gpu_proportion)\n",
    "            prop_time[col_names[1]].append(query_finish - query_start)\n",
    "            if clear_gpu_mem:\n",
    "                hdk.clear_gpu_mem()\n",
    "    df_output = result.to_arrow().to_pandas()\n",
    "    df_prop_time = pd.DataFrame(prop_time, columns=col_names)\n",
    "    return [df_prop_time, df_output]\n",
    "\n",
    "def run_queries_all_props(query_dict, step, n_iters, clear_gpu_mem=False):\n",
    "    \"\"\"\n",
    "    Runs query dictionary of SQL queries with the following structure: dict(query_name:{SQL_string})\n",
    "        clear_gpu_mem: when True, clear GPU memory between runs\n",
    "    \"\"\"\n",
    "    q_timings_df = pd.DataFrame()\n",
    "    # new_df = old_df[['a', 'b', 'c', 'd']]\n",
    "    for q_name in query_dict:\n",
    "        [df_prop_time, df_output] = run_single_q_all_props(\n",
    "            query_dict[q_name], \n",
    "            q_name=q_name, \n",
    "            prop_step=step, \n",
    "            n_iters=n_iters, \n",
    "            clear_gpu_mem=clear_gpu_mem\n",
    "        )\n",
    "        if q_timings_df.empty:\n",
    "            q_timings_df = df_prop_time\n",
    "            q_timings_df.rename(columns={q_name:f\"{q_name}_#RowsOut={df_output.shape[0]}\"}, inplace=True)\n",
    "        else:\n",
    "            q_timings_df[f\"{q_name}_#RowsOut={df_output.shape[0]}\"] = df_prop_time[q_name]\n",
    "    return q_timings_df\n",
    "\n",
    "def test_groups_fragment_sizes(\n",
    "        pyarrow_tbl, \n",
    "        table_name,\n",
    "        get_queries_for_table_callback, \n",
    "        step, \n",
    "        n_iters, \n",
    "        clear_memory_devices=False\n",
    "    ):\n",
    "    \"\"\" \n",
    "    Runs queries for different fragment sizes and returns a dictionary of structure: `frag_size: timings_df`\n",
    "    \"\"\"\n",
    "    \n",
    "    q_per_frag_size_df = pd.DataFrame()\n",
    "    for frag_size in fragment_size_test_range(pyarrow_tbl.num_rows):\n",
    "        table_rows = pyarrow_tbl.num_rows\n",
    "        print(f\"Testing {table_rows} rows table with Frag.size={frag_size}\")\n",
    "        refragmented_view_name = f\"{table_name}_{frag_size}\"\n",
    "        hdk.refragmented_view(table_name, frag_size, refragmented_view_name)\n",
    "        queries_timings = run_queries_all_props(\n",
    "            get_queries_for_table_callback(refragmented_view_name), \n",
    "            step, \n",
    "            n_iters, \n",
    "            clear_memory_devices\n",
    "        )\n",
    "        queries_timings[\"Frag.size\"]=frag_size\n",
    "        if q_per_frag_size_df.empty:\n",
    "            q_per_frag_size_df = queries_timings\n",
    "        else:\n",
    "            q_per_frag_size_df = pd.concat([q_per_frag_size_df, queries_timings])\n",
    "        hdk.drop_table(refragmented_view_name)\n",
    "        hdk.clear_gpu_mem()\n",
    "    return q_per_frag_size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data (replace with real dataset)\n",
    "dataset_path = \"../omniscidb/Tests/ArrowStorageDataFiles/taxi_sample_header.csv\"\n",
    "table_name = \"taxi\"\n",
    "# If the CSV does not have a header, please provide the column names.\n",
    "pyarrow_tbl = pa.csv.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries (NY Taxi example)\n",
    "def getTaxiQ_for_table(tbl_name):\n",
    "    return {\n",
    "    \"Q1\": f\"SELECT cab_type, count(*)\\\n",
    "            FROM {tbl_name}\\\n",
    "            GROUP BY cab_type;\",\n",
    "    \"Q2\": f\"SELECT passenger_count, avg(total_amount)\\\n",
    "            FROM {tbl_name}\\\n",
    "            GROUP BY passenger_count;\",\n",
    "    \"Q3\": f\"SELECT passenger_count, extract(year from pickup_datetime) as pickup_year, count(*)\\\n",
    "            FROM {tbl_name}\\\n",
    "            GROUP BY passenger_count, extract(year from pickup_datetime);\",\n",
    "    \"Q4\": f\"SELECT passenger_count,\\\n",
    "                extract(year from pickup_datetime) as pickup_year,\\\n",
    "                cast(trip_distance as int) AS distance,\\\n",
    "                count(*) AS the_count\\\n",
    "            FROM {tbl_name}\\\n",
    "            GROUP BY passenger_count,\\\n",
    "                    pickup_year,\\\n",
    "                    distance\\\n",
    "            ORDER BY passenger_count, pickup_year, distance, the_count;\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdk_tbl = import_hdk_pyarrow(pyarrow_tbl, table_name, fragment_size_calc(pyarrow_tbl.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_step = 25\n",
    "n_iters_per_prop = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_timings_df = run_queries_all_props(\n",
    "    getTaxiQ_for_table(table_name),\n",
    "    prop_step,\n",
    "    n_iters_per_prop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_per_frag_df = test_groups_fragment_sizes(\n",
    "    pyarrow_tbl,\n",
    "    table_name,\n",
    "    getTaxiQ_for_table,\n",
    "    prop_step,\n",
    "    n_iters_per_prop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "if importlib.util.find_spec(\"matplotlib\") is None:\n",
    "    raise Exception(\"Please install matplotlib\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (8,4)\n",
    "styles = ['s-','o-','^-','+-','*-',',-']\n",
    "\n",
    "def plotTimings(dict_of_df_timings, plot_name=\"Time vs GPU proportion\"):\n",
    "    ylab = \"Time (s)\"\n",
    "    xlab = \"Data proportion on GPU (%)\"\n",
    "    df_agg = dict_of_df_timings.groupby([\"GPU_prop\"]).median()\n",
    "    df_agg.plot(xlabel=xlab, ylabel=ylab, title=plot_name)\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plotTimingsFrags(timing_per_frag_df, default_frag_size = None, row_count = None, plot_name=\"Time vs GPU proportion\"):\n",
    "    ylab = \"Time (ms)\"\n",
    "    xlab = \"Data proportion on GPU (%)\"\n",
    "    fig, axes = plt.subplots(timing_per_frag_df.shape[1]-2,1)\n",
    "    fig.set_size_inches(7,9)\n",
    "    frag_sizes = timing_per_frag_df[\"Frag.size\"].unique()\n",
    "    for frag_size in frag_sizes:\n",
    "        frag_df = timing_per_frag_df[timing_per_frag_df[\"Frag.size\"]==frag_size].groupby([\"GPU_prop\"]).median()\n",
    "        frag_df = frag_df.drop(\"Frag.size\", axis=1)\n",
    "        frag_df *= 1000 \n",
    "        for enum, q_name in enumerate(frag_df):\n",
    "            df_agg = frag_df[q_name]\n",
    "            subplot_title = q_name\n",
    "            lab = f\"Frag.size={frag_size}\" if row_count is None else f\"Num.frags={int(np.ceil(row_count/frag_size))}\"\n",
    "            if default_frag_size is not None and default_frag_size == frag_size:\n",
    "                lab = f\"{lab} (CPU opt)\"\n",
    "            if frag_size == np.max(frag_sizes):\n",
    "                lab = f\"{lab} (GPU opt.)\"\n",
    "            df_agg.plot(\n",
    "                ax=axes[enum], \n",
    "                xlabel=xlab, \n",
    "                ylabel=ylab, \n",
    "                title=subplot_title, \n",
    "                style=styles[enum], \n",
    "                label=lab\n",
    "            )\n",
    "            axes[enum].legend(bbox_to_anchor=(1.01, 1.02), loc=\"upper left\")\n",
    "    fig.suptitle(plot_name)\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_frag_size = fragment_size_calc(pyarrow_tbl.num_rows)\n",
    "plotTimingsFrags(\n",
    "    timing_per_frag_df, \n",
    "    default_frag_size=default_frag_size, \n",
    "    row_count=pyarrow_tbl.num_rows,\n",
    "    plot_name=f\"Taxi, #Rows={pyarrow_tbl.num_rows//(1000*1000)}Mil.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDK Cleanup\n",
    "hdk.dropTable(table_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnisci-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
